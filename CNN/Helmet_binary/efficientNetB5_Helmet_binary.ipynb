{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"efficientNetB5_CNN.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"-t5HG-SigYxP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636777816549,"user_tz":-540,"elapsed":17514,"user":{"displayName":"Junny hi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEjHl3iEZdmO8l2rmXULfbj0fk2N-XZ7NECIwjow=s64","userId":"11763536325377287333"}},"outputId":"7467fde7-912b-49ca-c70b-6ed5669eedb4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nRlwWIx_18cO","executionInfo":{"status":"ok","timestamp":1636729062804,"user_tz":-540,"elapsed":417,"user":{"displayName":"Junny hi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEjHl3iEZdmO8l2rmXULfbj0fk2N-XZ7NECIwjow=s64","userId":"11763536325377287333"}},"outputId":"278b9463-840d-4593-9335-27fb0ff9c344"},"source":["%cd /content/drive/MyDrive/final_project_team8/현준/data"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1cFF5_9im4PZ2gSNoqz18KLMltfsx9SK3/final_project_team8/현준/data\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gWoCjk0lEc53","executionInfo":{"status":"ok","timestamp":1636729068827,"user_tz":-540,"elapsed":4256,"user":{"displayName":"Junny hi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEjHl3iEZdmO8l2rmXULfbj0fk2N-XZ7NECIwjow=s64","userId":"11763536325377287333"}},"outputId":"c046142a-2a50-423d-b353-ff24bc4c3622"},"source":["!git clone https://github.com/theAIGuysCode/OIDv4_ToolKit.git"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'OIDv4_ToolKit'...\n","remote: Enumerating objects: 444, done.\u001b[K\n","remote: Total 444 (delta 0), reused 0 (delta 0), pack-reused 444\u001b[K\n","Receiving objects: 100% (444/444), 34.09 MiB | 12.05 MiB/s, done.\n","Resolving deltas: 100% (157/157), done.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xO-8VU2TTNpl","executionInfo":{"status":"ok","timestamp":1636729080168,"user_tz":-540,"elapsed":9496,"user":{"displayName":"Junny hi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEjHl3iEZdmO8l2rmXULfbj0fk2N-XZ7NECIwjow=s64","userId":"11763536325377287333"}},"outputId":"496e3aca-9ae6-4cbf-de90-0c2e920d7fcb"},"source":["!pip3 install -r /content/drive/MyDrive/final_project_team8/현준/data/OIDv4_ToolKit/requirements.txt"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/final_project_team8/현준/data/OIDv4_ToolKit/requirements.txt (line 1)) (1.1.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/final_project_team8/현준/data/OIDv4_ToolKit/requirements.txt (line 2)) (1.19.5)\n","Collecting awscli\n","  Downloading awscli-1.22.4-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 4.1 MB/s \n","\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/final_project_team8/현준/data/OIDv4_ToolKit/requirements.txt (line 4)) (1.24.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/final_project_team8/현준/data/OIDv4_ToolKit/requirements.txt (line 5)) (4.62.3)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/final_project_team8/현준/data/OIDv4_ToolKit/requirements.txt (line 6)) (4.1.2.30)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r /content/drive/MyDrive/final_project_team8/현준/data/OIDv4_ToolKit/requirements.txt (line 1)) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r /content/drive/MyDrive/final_project_team8/현준/data/OIDv4_ToolKit/requirements.txt (line 1)) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->-r /content/drive/MyDrive/final_project_team8/현준/data/OIDv4_ToolKit/requirements.txt (line 1)) (1.15.0)\n","Collecting botocore==1.23.4\n","  Downloading botocore-1.23.4-py3-none-any.whl (8.1 MB)\n","\u001b[K     |████████████████████████████████| 8.1 MB 34.7 MB/s \n","\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 9.3 MB/s \n","\u001b[?25hCollecting docutils<0.16,>=0.10\n","  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n","\u001b[K     |████████████████████████████████| 547 kB 93.4 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML<5.5,>=3.10 in /usr/local/lib/python3.7/dist-packages (from awscli->-r /content/drive/MyDrive/final_project_team8/현준/data/OIDv4_ToolKit/requirements.txt (line 3)) (3.13)\n","Requirement already satisfied: rsa<4.8,>=3.1.2 in /usr/local/lib/python3.7/dist-packages (from awscli->-r /content/drive/MyDrive/final_project_team8/현준/data/OIDv4_ToolKit/requirements.txt (line 3)) (4.7.2)\n","Collecting colorama<0.4.4,>=0.2.5\n","  Downloading colorama-0.4.3-py2.py3-none-any.whl (15 kB)\n","Collecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting urllib3\n","  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 82.2 MB/s \n","\u001b[?25hRequirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<4.8,>=3.1.2->awscli->-r /content/drive/MyDrive/final_project_team8/현준/data/OIDv4_ToolKit/requirements.txt (line 3)) (0.4.8)\n","Installing collected packages: urllib3, jmespath, botocore, s3transfer, docutils, colorama, awscli\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: docutils\n","    Found existing installation: docutils 0.18\n","    Uninstalling docutils-0.18:\n","      Successfully uninstalled docutils-0.18\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.7 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed awscli-1.22.4 botocore-1.23.4 colorama-0.4.3 docutils-0.15.2 jmespath-0.10.0 s3transfer-0.5.0 urllib3-1.26.7\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QE7kJWwlatZW","executionInfo":{"status":"ok","timestamp":1636729115974,"user_tz":-540,"elapsed":792,"user":{"displayName":"Junny hi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEjHl3iEZdmO8l2rmXULfbj0fk2N-XZ7NECIwjow=s64","userId":"11763536325377287333"}},"outputId":"5a8b0539-77cf-4b21-aaca-6f8eb020f010"},"source":["%cd /content/drive/MyDrive/final_project_team8/현준/data/OIDv4_ToolKit"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1cFF5_9im4PZ2gSNoqz18KLMltfsx9SK3/final_project_team8/현준/data/OIDv4_ToolKit\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HxKxgJNATt9D","executionInfo":{"status":"ok","timestamp":1636730130433,"user_tz":-540,"elapsed":1008221,"user":{"displayName":"Junny hi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEjHl3iEZdmO8l2rmXULfbj0fk2N-XZ7NECIwjow=s64","userId":"11763536325377287333"}},"outputId":"0a6d8535-cf2f-45ea-a107-1a0dcb037124"},"source":["!python3 main.py downloader -y --classes Helmet --type_csv train --limit 2000"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[92m\n","\t\t   ___   _____  ______            _    _    \n","\t\t .'   `.|_   _||_   _ `.         | |  | |   \n","\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n","\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n","\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n","\t\t `.___.'|_____||______.'   \\__/     |_____|\n","\t\u001b[0m\n","\u001b[92m\n","             _____                    _                 _             \n","            (____ \\                  | |               | |            \n","             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n","            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n","            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n","            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n","                                                          \n","        \u001b[0m\n","    [INFO] | Downloading Helmet.\u001b[0m\n","\u001b[91m   [ERROR] | Missing the class-descriptions-boxable.csv file.\u001b[0m\n","\u001b[94m[DOWNLOAD] | Automatic download.\u001b[0m\n","...145%, 0 MB, 53944 KB/s, 0 seconds passed\n","\u001b[94m[DOWNLOAD] | File class-descriptions-boxable.csv downloaded into OID/csv_folder/class-descriptions-boxable.csv.\u001b[0m\n","\u001b[91m   [ERROR] | Missing the train-annotations-bbox.csv file.\u001b[0m\n","\u001b[94m[DOWNLOAD] | Automatic download.\u001b[0m\n","...100%, 1138 MB, 24742 KB/s, 47 seconds passed\n","\u001b[94m[DOWNLOAD] | File train-annotations-bbox.csv downloaded into OID/csv_folder/train-annotations-bbox.csv.\u001b[0m\n","\n","\u001b[95mHelmet\u001b[0m\n","    [INFO] | Downloading train images.\u001b[0m\n","    [INFO] | [INFO] Found 7608 online images for train.\u001b[0m\n","    [INFO] | Limiting to 2000 images.\u001b[0m\n","    [INFO] | Download of 2000 images in train.\u001b[0m\n","100% 2000/2000 [14:59<00:00,  2.22it/s]\n","    [INFO] | Done!\u001b[0m\n","    [INFO] | Creating labels for Helmet of train.\u001b[0m\n","    [INFO] | Labels creation completed.\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dBPQuo2h28Yj","outputId":"ddd62ad4-6aaa-41e2-8326-fa8575e65f90"},"source":["!pwd"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1cFF5_9im4PZ2gSNoqz18KLMltfsx9SK3/final_project_team8/현준/data/OIDv4_ToolKit\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kDQfdFs23EA2","executionInfo":{"status":"ok","timestamp":1636730175975,"user_tz":-540,"elapsed":513,"user":{"displayName":"Junny hi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEjHl3iEZdmO8l2rmXULfbj0fk2N-XZ7NECIwjow=s64","userId":"11763536325377287333"}},"outputId":"380c88df-8483-4cca-f69e-c379a9da8643"},"source":["%cd /content/drive/MyDrive/final_project_team8/현준/data/OIDv4_ToolKit/"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1cFF5_9im4PZ2gSNoqz18KLMltfsx9SK3/final_project_team8/현준/data/OIDv4_ToolKit\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4dQDCV_bJuSz","executionInfo":{"status":"ok","timestamp":1636731364441,"user_tz":-540,"elapsed":1177607,"user":{"displayName":"Junny hi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEjHl3iEZdmO8l2rmXULfbj0fk2N-XZ7NECIwjow=s64","userId":"11763536325377287333"}},"outputId":"5fa28820-7024-4dd2-806f-7525a907e343"},"source":["!python3 main.py downloader -y --classes Human_face --type_csv train --limit 2000"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[92m\n","\t\t   ___   _____  ______            _    _    \n","\t\t .'   `.|_   _||_   _ `.         | |  | |   \n","\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n","\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n","\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n","\t\t `.___.'|_____||______.'   \\__/     |_____|\n","\t\u001b[0m\n","\u001b[92m\n","             _____                    _                 _             \n","            (____ \\                  | |               | |            \n","             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n","            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n","            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n","            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n","                                                          \n","        \u001b[0m\n","    [INFO] | Downloading Human face.\u001b[0m\n","\n","\u001b[95mHuman face\u001b[0m\n","    [INFO] | Downloading train images.\u001b[0m\n","    [INFO] | [INFO] Found 331627 online images for train.\u001b[0m\n","    [INFO] | Limiting to 2000 images.\u001b[0m\n","    [INFO] | Download of 2000 images in train.\u001b[0m\n","100% 2000/2000 [14:53<00:00,  2.24it/s]\n","    [INFO] | Done!\u001b[0m\n","    [INFO] | Creating labels for Human face of train.\u001b[0m\n","    [INFO] | Labels creation completed.\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"a4Hg0VugHMOR"},"source":["# x ,x+w ,y ,y+h"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AnY2OYpyJOVZ"},"source":["from tqdm import tqdm\n","from PIL import Image\n","import cv2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Y7SviyHN8YF"},"source":["from google.colab.patches import cv2_imshow\n","# 이미지 불러오기\n","# img = cv2.imread('/content/OIDv4_ToolKit/OID/Dataset/train/Helmet/002fbe3379025cf1.jpg',cv2.IMREAD_COLOR)\n","# gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","img = cv2.imread('/content/drive/MyDrive/final_project_team8/현준/data/OIDv4_ToolKit/OID/Dataset/train/Helmet/0026ee2e98601bf4.jpg')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":169},"id":"oKn6PU6LRxvs","executionInfo":{"status":"error","timestamp":1636731420729,"user_tz":-540,"elapsed":6,"user":{"displayName":"Junny hi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEjHl3iEZdmO8l2rmXULfbj0fk2N-XZ7NECIwjow=s64","userId":"11763536325377287333"}},"outputId":"a795dc7a-17d7-4bcc-b736-5d5a46eba0ac"},"source":["cv2_imshow(img[201:298, 325:414])"],"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-a8ab4ff8cc78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m201\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m298\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m325\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m414\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"]}]},{"cell_type":"code","metadata":{"id":"xidYj53GTKiP"},"source":["from glob import glob\n","helmet_label = glob(\"/content/drive/MyDrive/final_project_team8/현준/data/OIDv4_ToolKit/OID/Dataset/train/Helmet/Label/*.txt\")\n","human_face_label = glob('/content/drive/MyDrive/final_project_team8/현준/data/OIDv4_ToolKit/OID/Dataset/train/Human face/Label/*.txt')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8IQfmyIT4wE3"},"source":["human_face_label"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qDCsU-MY964-"},"source":["image_path ='/content/drive/MyDrive/final_project_team8/현준/data/OIDv4_ToolKit/OID/Dataset/train/Helmet/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RJ_8wx9Azw3n"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BHvljPxjRpjD"},"source":["img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CWxtmLap5Gad"},"source":["# image_path : 이미지가 있는 경로\n","# label_path : 좌표값 txt가 있는 경로\n","# save_path : crop 이미지 저장할\n","\n","# for i in tqdm(range(len(human_face_label))):\n","for i in range(len(human_face_label)):\n","    with open(human_face_label[i]) as f:\n","        # .txt를 제거한 파일 이름만 추출\n","        #  ex) f993aefbee7c9b59\n","        img_name = human_face_label[i].split('Label/')[1].split('.txt')[0]\n","\n","        # 추출한 이름에 .jpg\n","        img_name = img_name +'.jpg'\n","\n","        # 이미지 경로 + 이미지 이름\n","        img = cv2.imread(base_path + img_name)\n","\n","        # 한 이미지당 2개 이상의 좌표시 번호 붙이기\n","        cnt = 0\n","        for line in f.read().splitlines():\n","            print(line)\n","            # 텍스트 폴더에서 클래스 이름뺴고 좌표만 추출, 뒤에서 4개\n","            # 좌표값이 문자열형태임 -> 실수형\n","            x ,y , xw, yh = list(map(float,line.split()[-4:]))\n","\n","            # path : crop 이미지 저장폴더\n","            path = '/content/img/'\n","\n","            # 저장\n","            cv2.imwrite(path + f'{str(cnt)}{img_name}',img[int(y):int(yh),int(x): int(xw)])\n","            # 중복안되게 cnt 증가\n","            cnt +=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7wxaDpXpIRuI","outputId":"61a93ff2-f0ad-4b04-f7dc-28c878da440f"},"source":["from glob import glob\n","crop_img = glob(\"/content/img/*.jpg\")\n","print(len(crop_img))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["297\n"]}]},{"cell_type":"code","metadata":{"id":"mvelBK3g6I8p"},"source":["# image_path : 이미지가 있는 경로\n","# label_path : 좌표값 txt가 있는 경로\n","# save_path : crop 이미지 저장할 경로\n","\n","def image_crop(image_path, label_path,save_path):\n","    label = glob(label_path + \"*.txt\")\n","\n","    for i in tqdm(range(len(label))):\n","        with open(label[i]) as f:\n","            # .txt를 제거한 파일 이름만 추출\n","            #  ex) f993aefbee7c9b59\n","            img_name = label[i].split('Label/')[1].split('.txt')[0]\n","\n","            # 추출한 이름에 .jpg\n","            img_name = img_name +'.jpg'\n","\n","            # 이미지 경로 + 이미지 이름\n","            img = cv2.imread(image_path + img_name)\n","\n","            # 한 이미지당 2개 이상의 좌표시 번호 붙이기\n","            cnt = 0\n","            for line in f.read().splitlines():\n","                # 텍스트 폴더에서 클래스 이름뺴고 좌표만 추출, 뒤에서 4개\n","                # 좌표값이 문자열형태임 -> 실수형\n","                x ,y , xw, yh = list(map(float,line.split()[-4:]))\n","\n","                # path : crop 이미지 저장폴더\n","                path = save_path\n","\n","                # 저장\n","                cv2.imwrite(path + f'{str(cnt)}{img_name}',img[int(y):int(yh),int(x): int(xw)])\n","                # 중복안되게 cnt 증가\n","                cnt +=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_wlX42kw0LDo"},"source":["from glob import glob"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_CAowJkmT8UV","executionInfo":{"status":"ok","timestamp":1636731825481,"user_tz":-540,"elapsed":61245,"user":{"displayName":"Junny hi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEjHl3iEZdmO8l2rmXULfbj0fk2N-XZ7NECIwjow=s64","userId":"11763536325377287333"}},"outputId":"6203f976-22b1-42b3-b2d9-47134b92d885"},"source":["image_path ='/content/drive/MyDrive/final_project_team8/현준/data/OIDv4_ToolKit/OID/Dataset/train/Helmet/'\n","Helmet_label = '/content/drive/MyDrive/final_project_team8/현준/data/OIDv4_ToolKit/OID/Dataset/train/Helmet/Label/'\n","save_path = '/content/drive/MyDrive/final_project_team8/현준/data/crop/yes/'\n","\n","# 함수실행\n","image_crop(image_path, Helmet_label, save_path)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 2000/2000 [01:00<00:00, 32.94it/s]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pWF8gUn40SbI","executionInfo":{"status":"ok","timestamp":1636731828389,"user_tz":-540,"elapsed":412,"user":{"displayName":"Junny hi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEjHl3iEZdmO8l2rmXULfbj0fk2N-XZ7NECIwjow=s64","userId":"11763536325377287333"}},"outputId":"2dcfb72b-ed23-4bbd-f978-9f7c5a533c97"},"source":["crop_img = glob(\"/content/drive/MyDrive/final_project_team8/현준/data/crop/yes/*.jpg\")\n","print(len(crop_img))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4476\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Czv4OrZkzwiO","executionInfo":{"status":"ok","timestamp":1636731896007,"user_tz":-540,"elapsed":65916,"user":{"displayName":"Junny hi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEjHl3iEZdmO8l2rmXULfbj0fk2N-XZ7NECIwjow=s64","userId":"11763536325377287333"}},"outputId":"68f33392-457b-46d8-f9e5-0a3aff7a3404"},"source":["image_path ='/content/drive/MyDrive/final_project_team8/현준/data/OIDv4_ToolKit/OID/Dataset/train/Human face/'\n","human_face_label = '/content/drive/MyDrive/final_project_team8/현준/data/OIDv4_ToolKit/OID/Dataset/train/Human face/Label/'\n","save_path = '/content/drive/MyDrive/final_project_team8/현준/data/crop/no/'\n","\n","# 함수실행\n","image_crop(image_path, human_face_label, save_path)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 2000/2000 [01:05<00:00, 30.55it/s]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vJZikN-g0WLb","executionInfo":{"status":"ok","timestamp":1636731904646,"user_tz":-540,"elapsed":802,"user":{"displayName":"Junny hi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEjHl3iEZdmO8l2rmXULfbj0fk2N-XZ7NECIwjow=s64","userId":"11763536325377287333"}},"outputId":"6331c347-c5b9-473b-c88a-453256aaaa21"},"source":["crop_img = glob(\"/content/drive/MyDrive/final_project_team8/현준/data/crop/no/*.jpg\")\n","print(len(crop_img))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["5761\n"]}]},{"cell_type":"markdown","metadata":{"id":"DJsvqA6_JvZG"},"source":["# X_train, y_train"]},{"cell_type":"code","metadata":{"id":"YhOOAHr1J3EU"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NTeU_iUt1KiM"},"source":["from tensorflow.keras.applications import EfficientNetB5\n","from keras.models import Sequential, Model\n","from keras import layers\n","from keras import Input\n","from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n","import tensorflow as tf\n","from tensorflow.keras.optimizers import Adam\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ln-wx5Ii4WTI","executionInfo":{"status":"ok","timestamp":1636775243243,"user_tz":-540,"elapsed":8796,"user":{"displayName":"Junny hi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEjHl3iEZdmO8l2rmXULfbj0fk2N-XZ7NECIwjow=s64","userId":"11763536325377287333"}},"outputId":"d5fe74b3-7b4d-4584-c710-26541b267da5"},"source":["# EfficientNetB5 = EfficientNetB5(\n","#     weights='imagenet', \n","#     include_top=False, \n","#     input_shape=(456,456, 3),\n","#     drop_connect_rate=0.4\n","# )"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb5_notop.h5\n","115269632/115263384 [==============================] - 1s 0us/step\n","115277824/115263384 [==============================] - 1s 0us/step\n"]}]},{"cell_type":"code","metadata":{"id":"WBUWgwiC4iSn"},"source":["EfficientNetB5.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"87q5-cJYIF4g"},"source":["input_shape=(456,456, 3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gUB3sfbwFMve"},"source":["model = tf.keras.Sequential()\n","model.add(tf.keras.applications.EfficientNetB5(include_top=False, weights='imagenet', input_shape=input_shape, drop_connect_rate=0.4))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.8))\n","model.add(Dense(1, activation='sigmoid'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AKtcLsOMHQv9","executionInfo":{"status":"ok","timestamp":1636780175763,"user_tz":-540,"elapsed":6,"user":{"displayName":"Junny hi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEjHl3iEZdmO8l2rmXULfbj0fk2N-XZ7NECIwjow=s64","userId":"11763536325377287333"}},"outputId":"502ae8aa-3d93-4333-97a3-0a25fc902000"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," efficientnetb5 (Functional)  (None, 15, 15, 2048)     28513527  \n","                                                                 \n"," flatten_4 (Flatten)         (None, 460800)            0         \n","                                                                 \n"," dense_11 (Dense)            (None, 128)               58982528  \n","                                                                 \n"," dropout_7 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_12 (Dense)            (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 87,496,184\n","Trainable params: 87,323,441\n","Non-trainable params: 172,743\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"hwtrmPbAI9TB"},"source":["model.compile(loss = 'binary_crossentropy',  #binary_crossentropy\n","              optimizer = Adam(learning_rate = 1e-4),\n","              metrics = ['acc']\n","              )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"97zzWEdBtT9a"},"source":["from keras.models import load_model, save_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mnWO6C3VfYIr","executionInfo":{"status":"ok","timestamp":1636776716589,"user_tz":-540,"elapsed":291,"user":{"displayName":"Junny hi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEjHl3iEZdmO8l2rmXULfbj0fk2N-XZ7NECIwjow=s64","userId":"11763536325377287333"}},"outputId":"a1262141-e98e-4615-85ec-e53ac182140e"},"source":["cd /content\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","metadata":{"id":"t7z3u5Vgfrxb"},"source":["mkdir check"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AnOgoVbqkOS2"},"source":["# checkpoint 만들기\n","checkpoint_path = '/content/check/tmp_checkpoint.ckpt'\n","\n","checkpoint = ModelCheckpoint(\n","    filepath=checkpoint_path\n","    ,save_weights_only=True\n","    ,save_best_only=True\n","    ,monitor='loss' # val_loss\n","    ,verbose=1\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6z1ifrdjKUUF"},"source":["train_path = '/content/drive/MyDrive/final_project_team8/현준/data/train_crop/'\n","test_path = '/content/drive/MyDrive/final_project_team8/현준/data/test_crop/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xe_mmhIfPDQk"},"source":["# 1만 데이터\n","train_DIR = '/content/drive/MyDrive/cut_data_limit10000/train/'\n","test_DIR = '/content/drive/MyDrive/cut_data_limit10000/test/'\n","val_DIR = '/content/drive/MyDrive/cut_data_limit10000/validation/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wC5rLVzGkdwh"},"source":["from tensorflow.keras.callbacks import ModelCheckpoint"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OKluUkomK9jV","executionInfo":{"status":"ok","timestamp":1636780186395,"user_tz":-540,"elapsed":2147,"user":{"displayName":"Junny hi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEjHl3iEZdmO8l2rmXULfbj0fk2N-XZ7NECIwjow=s64","userId":"11763536325377287333"}},"outputId":"af5525ed-085a-4a70-8b60-d660bf542568"},"source":["# 데이터셋 이미지 로드\n","train_datagen = ImageDataGenerator(\n","    rescale = 1/255\n","    )\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_DIR,\n","    target_size = (456,456),\n","    batch_size = 1,\n","    class_mode = 'binary',\n","    shuffle = True\n",")\n","\n","# 테스트셋\n","test_datagen = ImageDataGenerator(\n","    rescale = 1/255\n","    )\n","test_generator = test_datagen.flow_from_directory(\n","    test_DIR,\n","    target_size = (456,456),\n","    batch_size = 1,\n","    class_mode = 'binary',\n","    shuffle = False\n",")\n","\n","val_datagen = ImageDataGenerator(\n","                        rescale = 1/255\n","                    )\n","val_generator = val_datagen.flow_from_directory(\n","                        val_DIR,\n","                        target_size=(456, 456),\n","                        batch_size=1,\n","                        class_mode=\"binary\",\n","                        shuffle=False\n","                    )"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 48301 images belonging to 2 classes.\n","Found 17201 images belonging to 2 classes.\n","Found 5757 images belonging to 2 classes.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6QxvuSI1mUSP","executionInfo":{"status":"ok","timestamp":1636790204532,"user_tz":-540,"elapsed":10006657,"user":{"displayName":"Junny hi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEjHl3iEZdmO8l2rmXULfbj0fk2N-XZ7NECIwjow=s64","userId":"11763536325377287333"}},"outputId":"3bffdc2d-bbfe-4644-f687-6a8ceb5127b2"},"source":["# 이미지 학습\n","model.fit(\n","\ttrain_generator\n","\t,validation_data=val_generator\n"," \t,batch_size= 640\n","\t,steps_per_epoch = 46666 // 640 # lr : 1e-3\n","\t,epochs = 50 \n","\t# ,callbacks=[checkpoint]\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","72/72 [==============================] - 624s 9s/step - loss: 3.4485 - acc: 0.5556 - val_loss: 1.7622 - val_acc: 0.8980\n","Epoch 2/50\n","72/72 [==============================] - 192s 3s/step - loss: 2.6071 - acc: 0.6806 - val_loss: 1.5668 - val_acc: 0.8980\n","Epoch 3/50\n","72/72 [==============================] - 193s 3s/step - loss: 2.6093 - acc: 0.7083 - val_loss: 0.6524 - val_acc: 0.7810\n","Epoch 4/50\n","72/72 [==============================] - 191s 3s/step - loss: 3.3033 - acc: 0.7361 - val_loss: 2.3202 - val_acc: 0.8980\n","Epoch 5/50\n","72/72 [==============================] - 189s 3s/step - loss: 2.4029 - acc: 0.7778 - val_loss: 1.1068 - val_acc: 0.5960\n","Epoch 6/50\n","72/72 [==============================] - 192s 3s/step - loss: 3.2452 - acc: 0.7500 - val_loss: 0.5754 - val_acc: 0.8850\n","Epoch 7/50\n","72/72 [==============================] - 190s 3s/step - loss: 2.7764 - acc: 0.7778 - val_loss: 1.4531 - val_acc: 0.8977\n","Epoch 8/50\n","72/72 [==============================] - 192s 3s/step - loss: 2.3841 - acc: 0.8056 - val_loss: 0.9792 - val_acc: 0.9006\n","Epoch 9/50\n","72/72 [==============================] - 189s 3s/step - loss: 2.5139 - acc: 0.7083 - val_loss: 6.4404 - val_acc: 0.2376\n","Epoch 10/50\n","72/72 [==============================] - 190s 3s/step - loss: 1.3205 - acc: 0.8611 - val_loss: 1.3171 - val_acc: 0.6019\n","Epoch 11/50\n","72/72 [==============================] - 188s 3s/step - loss: 2.3407 - acc: 0.7917 - val_loss: 2.7142 - val_acc: 0.3387\n","Epoch 12/50\n","72/72 [==============================] - 190s 3s/step - loss: 0.6656 - acc: 0.8611 - val_loss: 3.4567 - val_acc: 0.2826\n","Epoch 13/50\n","72/72 [==============================] - 191s 3s/step - loss: 0.5251 - acc: 0.8889 - val_loss: 0.8216 - val_acc: 0.7275\n","Epoch 14/50\n","72/72 [==============================] - 188s 3s/step - loss: 0.4509 - acc: 0.9167 - val_loss: 0.6462 - val_acc: 0.8991\n","Epoch 15/50\n","72/72 [==============================] - 189s 3s/step - loss: 1.1941 - acc: 0.8056 - val_loss: 0.4352 - val_acc: 0.9036\n","Epoch 16/50\n","72/72 [==============================] - 195s 3s/step - loss: 0.9379 - acc: 0.8750 - val_loss: 0.8650 - val_acc: 0.6991\n","Epoch 17/50\n","72/72 [==============================] - 194s 3s/step - loss: 0.4547 - acc: 0.9444 - val_loss: 1.2626 - val_acc: 0.7030\n","Epoch 18/50\n","72/72 [==============================] - 193s 3s/step - loss: 1.0044 - acc: 0.8472 - val_loss: 2.0990 - val_acc: 0.5260\n","Epoch 19/50\n","72/72 [==============================] - 192s 3s/step - loss: 1.2847 - acc: 0.8472 - val_loss: 4.2538 - val_acc: 0.2776\n","Epoch 20/50\n","72/72 [==============================] - 197s 3s/step - loss: 0.3662 - acc: 0.8889 - val_loss: 1.3034 - val_acc: 0.5948\n","Epoch 21/50\n","72/72 [==============================] - 192s 3s/step - loss: 0.3625 - acc: 0.9306 - val_loss: 2.1002 - val_acc: 0.5088\n","Epoch 22/50\n","72/72 [==============================] - 205s 3s/step - loss: 0.8771 - acc: 0.8750 - val_loss: 0.5158 - val_acc: 0.8044\n","Epoch 23/50\n","72/72 [==============================] - 191s 3s/step - loss: 0.3805 - acc: 0.8889 - val_loss: 3.2016 - val_acc: 0.2923\n","Epoch 24/50\n","72/72 [==============================] - 193s 3s/step - loss: 0.3400 - acc: 0.9028 - val_loss: 1.5104 - val_acc: 0.5828\n","Epoch 25/50\n","72/72 [==============================] - 191s 3s/step - loss: 0.4271 - acc: 0.8889 - val_loss: 0.5365 - val_acc: 0.7592\n","Epoch 26/50\n","72/72 [==============================] - 190s 3s/step - loss: 0.9055 - acc: 0.8194 - val_loss: 0.9207 - val_acc: 0.6220\n","Epoch 27/50\n","72/72 [==============================] - 196s 3s/step - loss: 0.5135 - acc: 0.8750 - val_loss: 0.3321 - val_acc: 0.8617\n","Epoch 28/50\n","72/72 [==============================] - 192s 3s/step - loss: 0.5634 - acc: 0.8194 - val_loss: 1.3641 - val_acc: 0.4440\n","Epoch 29/50\n","72/72 [==============================] - 193s 3s/step - loss: 0.4211 - acc: 0.8611 - val_loss: 2.8360 - val_acc: 0.1669\n","Epoch 30/50\n","72/72 [==============================] - 190s 3s/step - loss: 0.8828 - acc: 0.7361 - val_loss: 1.8837 - val_acc: 0.2170\n","Epoch 31/50\n","72/72 [==============================] - 190s 3s/step - loss: 0.3338 - acc: 0.8889 - val_loss: 2.0732 - val_acc: 0.2962\n","Epoch 32/50\n","72/72 [==============================] - 190s 3s/step - loss: 0.5059 - acc: 0.8889 - val_loss: 0.9213 - val_acc: 0.4945\n","Epoch 33/50\n","72/72 [==============================] - 188s 3s/step - loss: 0.3227 - acc: 0.8889 - val_loss: 0.3154 - val_acc: 0.8584\n","Epoch 34/50\n","72/72 [==============================] - 190s 3s/step - loss: 0.5697 - acc: 0.7917 - val_loss: 1.0537 - val_acc: 0.4501\n","Epoch 35/50\n","72/72 [==============================] - 189s 3s/step - loss: 0.2710 - acc: 0.9167 - val_loss: 2.0238 - val_acc: 0.2595\n","Epoch 36/50\n","72/72 [==============================] - 189s 3s/step - loss: 0.3340 - acc: 0.8611 - val_loss: 1.5828 - val_acc: 0.3033\n","Epoch 37/50\n","72/72 [==============================] - 190s 3s/step - loss: 0.5250 - acc: 0.8333 - val_loss: 2.5087 - val_acc: 0.1067\n","Epoch 38/50\n","72/72 [==============================] - 189s 3s/step - loss: 0.4205 - acc: 0.8472 - val_loss: 0.8775 - val_acc: 0.5089\n","Epoch 39/50\n","72/72 [==============================] - 190s 3s/step - loss: 0.1604 - acc: 0.9028 - val_loss: 0.6820 - val_acc: 0.6319\n","Epoch 40/50\n","72/72 [==============================] - 188s 3s/step - loss: 0.2838 - acc: 0.9444 - val_loss: 0.9559 - val_acc: 0.5882\n","Epoch 41/50\n","72/72 [==============================] - 189s 3s/step - loss: 2.7176 - acc: 0.7361 - val_loss: 0.7230 - val_acc: 0.5452\n","Epoch 42/50\n","72/72 [==============================] - 194s 3s/step - loss: 0.3932 - acc: 0.8056 - val_loss: 0.2090 - val_acc: 0.9232\n","Epoch 43/50\n","72/72 [==============================] - 189s 3s/step - loss: 0.3864 - acc: 0.8750 - val_loss: 0.4637 - val_acc: 0.8543\n","Epoch 44/50\n","72/72 [==============================] - 189s 3s/step - loss: 0.4498 - acc: 0.8472 - val_loss: 0.5475 - val_acc: 0.7388\n","Epoch 45/50\n","72/72 [==============================] - 189s 3s/step - loss: 0.6392 - acc: 0.8750 - val_loss: 0.8041 - val_acc: 0.3363\n","Epoch 46/50\n","72/72 [==============================] - 190s 3s/step - loss: 0.2531 - acc: 0.8611 - val_loss: 0.5580 - val_acc: 0.7004\n","Epoch 47/50\n","72/72 [==============================] - 189s 3s/step - loss: 0.2053 - acc: 0.9444 - val_loss: 0.6866 - val_acc: 0.5637\n","Epoch 48/50\n","72/72 [==============================] - 189s 3s/step - loss: 0.3120 - acc: 0.8750 - val_loss: 0.3328 - val_acc: 0.8859\n","Epoch 49/50\n","72/72 [==============================] - 188s 3s/step - loss: 0.2121 - acc: 0.9028 - val_loss: 0.2306 - val_acc: 0.9093\n","Epoch 50/50\n","72/72 [==============================] - 190s 3s/step - loss: 0.5111 - acc: 0.8750 - val_loss: 0.1307 - val_acc: 0.9557\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f11c518d350>"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bQJ9uL4NNZw2","executionInfo":{"status":"ok","timestamp":1636771545493,"user_tz":-540,"elapsed":25884,"user":{"displayName":"Junny hi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEjHl3iEZdmO8l2rmXULfbj0fk2N-XZ7NECIwjow=s64","userId":"11763536325377287333"}},"outputId":"29eb068f-f0d9-4ca6-ffeb-00350aca0bc5"},"source":["model.fit(\n","\ttrain_generator\n"," \t,batch_size=10\n","\t,steps_per_epoch = 8 # lr : 1e-5\n","\t,epochs=400\n","\t# ,callbacks=[checkpoint]\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","1/1 [==============================] - 25s 25s/step - loss: 0.0445 - acc: 1.0000\n","Epoch 2/2\n","1/1 [==============================] - 0s 404ms/step - loss: 0.8660 - acc: 0.0000e+00\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f88f8f37ad0>"]},"metadata":{},"execution_count":85}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":404},"id":"CbQlXfI7tDgV","executionInfo":{"status":"error","timestamp":1636793314249,"user_tz":-540,"elapsed":88119,"user":{"displayName":"Junny hi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEjHl3iEZdmO8l2rmXULfbj0fk2N-XZ7NECIwjow=s64","userId":"11763536325377287333"}},"outputId":"7f752848-ab69-47fd-dd71-456f1ae4ae3a"},"source":["# 이미지 테스트\n","model.evaluate(\n","\ttest_generator\n","    , batch_size = 640 # epochs=500\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["12649/17201 [=====================>........] - ETA: 18:20 - loss: 0.1529 - acc: 0.9442"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-50-6ce82d6b5826>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m model.evaluate(\n\u001b[1;32m      3\u001b[0m         \u001b[0mtest_generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m640\u001b[0m \u001b[0;31m# epochs=500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1538\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    947\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"d1ArVK-TxA_l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636793323522,"user_tz":-540,"elapsed":5742,"user":{"displayName":"Junny hi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEjHl3iEZdmO8l2rmXULfbj0fk2N-XZ7NECIwjow=s64","userId":"11763536325377287333"}},"outputId":"3fbe1917-26dd-4cbb-c3e2-99fe86425b50"},"source":["model.save(\"/content/drive/MyDrive/final_project_team8/현준/eff.h5\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]}]},{"cell_type":"markdown","metadata":{"id":"xBV90NI4hcnJ"},"source":["# efficientV2-L"]},{"cell_type":"code","metadata":{"id":"MOHy962Jhfq7"},"source":["import copy\n","import math\n","\n","from keras import backend\n","from keras import layers\n","from keras.applications import imagenet_utils\n","from keras.engine import training\n","from keras.utils import data_utils\n","from keras.utils import layer_utils\n","import tensorflow.compat.v2 as tf\n","from tensorflow.python.util.tf_export import keras_export"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QmydByG9hktS"},"source":["# image_path : 이미지가 있는 경로\n","# label_path : 좌표값 txt가 있는 경로\n","# save_path : crop 이미지 저장할\n","\n","# for i in tqdm(range(len(human_face_label))):\n","for i in range(len(human_face_label)):\n","    with open(human_face_label[i]) as f:\n","        # .txt를 제거한 파일 이름만 추출\n","        #  ex) f993aefbee7c9b59\n","        img_name = human_face_label[i].split('Label/')[1].split('.txt')[0]\n","\n","        # 추출한 이름에 .jpg\n","        img_name = img_name +'.jpg'\n","\n","        # 이미지 경로 + 이미지 이름\n","        img = cv2.imread(base_path + img_name)\n","\n","        # 한 이미지당 2개 이상의 좌표시 번호 붙이기\n","        cnt = 0\n","        for line in f.read().splitlines():\n","            print(line)\n","            # 텍스트 폴더에서 클래스 이름뺴고 좌표만 추출, 뒤에서 4개\n","            # 좌표값이 문자열형태임 -> 실수형\n","            x ,y , xw, yh = list(map(float,line.split()[-4:]))\n","\n","            # path : crop 이미지 저장폴더\n","            path = '/content/img/'\n","\n","            # 저장\n","            cv2.imwrite(path + f'{str(cnt)}{img_name}',img[int(y):int(yh),int(x): int(xw)])\n","            # 중복안되게 cnt 증가\n","            cnt +=1"],"execution_count":null,"outputs":[]}]}