{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e915b3dc-df00-49dd-8627-956a42b2a8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/mobilenet_v2_ssdlite_keras\n"
     ]
    }
   ],
   "source": [
    "%cd /root/mobilenet_v2_ssdlite_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59161772-9753-4605-86aa-93683ebb4d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/root/mobilenet_v2_ssdlite_keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fae349d-a98c-44d7-8036-4dfebd37bdbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 08:50:51.225770: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from losses.keras_ssd_loss import SSDLoss\n",
    "from utils.object_detection_2d_data_generator import DataGenerator\n",
    "from utils.object_detection_2d_geometric_ops import Resize\n",
    "from utils.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from utils.data_augmentation_chain_original_ssd import SSDDataAugmentation\n",
    "from utils.coco import get_coco_category_maps\n",
    "from utils.ssd_input_encoder import SSDInputEncoder\n",
    "# from models.keras_mobilenet_v2_ssdlite import mobilenet_v2_ssd\n",
    "from layers.AnchorBoxesLayer import AnchorBoxes\n",
    "from layers.DecodeDetectionsLayer import DecodeDetections\n",
    "from layers.DecodeDetectionsFastLayer import DecodeDetectionsFast\n",
    "from models.graphs.mobilenet_v2_ssdlite_praph import mobilenet_v2_ssdlite\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import backend as K \n",
    "from tensorflow.keras.layers import Input, Lambda, Activation, Conv2D, \\\n",
    "    DepthwiseConv2D, Reshape, Concatenate, BatchNormalization, ReLU\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, LearningRateScheduler, TerminateOnNaN, CSVLogger\n",
    "from glob import glob\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39dc7197-99f5-482f-b48f-d8b9f7ff3579",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d65f7e69-363c-4704-9c99-9bd6838fe0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model config\n",
    "batch_size = 128\n",
    "image_size = (256, 256, 3)\n",
    "n_classes = 4\n",
    "mode = 'training'\n",
    "l2_regularization = 0.0005\n",
    "min_scale = 0.1\n",
    "max_scale = 0.9\n",
    "scales_pascal = [0.1, 0.2, 0.37, 0.54, 0.71, 0.88, 1.05]\n",
    "scales = scales_pascal\n",
    "aspect_ratios_global = None\n",
    "aspect_ratios  = [[1.0, 2.0, 0.5], \n",
    "                [1.0, 2.0, 0.5, 3.0, 1.0 / 3.0], \n",
    "                [1.0, 2.0, 0.5, 3.0, 1.0 / 3.0],\n",
    "                [1.0, 2.0, 0.5, 3.0, 1.0 / 3.0], \n",
    "                [1.0, 2.0, 0.5], \n",
    "                [1.0, 2.0, 0.5]]\n",
    "two_boxes_for_ar1 = True\n",
    "steps = None\n",
    "offsets = None\n",
    "clip_boxes = False\n",
    "variances = [0.1, 0.1, 0.2, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3eaeee7-0ac7-4f48-92b7-1b46b81de855",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 08:51:03.659851: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-11 08:51:03.661421: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-11 08:51:04.184742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-11 08:51:04.185619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-12-11 08:51:04.185673: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-12-11 08:51:04.190387: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-12-11 08:51:04.190508: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-12-11 08:51:04.192349: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-11 08:51:04.192833: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-11 08:51:04.200955: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-11 08:51:04.202030: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-12-11 08:51:04.202308: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-12-11 08:51:04.202485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-11 08:51:04.203389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-11 08:51:04.204155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-12-11 08:51:04.204858: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-11 08:51:04.206349: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-11 08:51:04.206560: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-11 08:51:04.207362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-12-11 08:51:04.207402: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-12-11 08:51:04.207438: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-12-11 08:51:04.207457: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-12-11 08:51:04.207474: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-11 08:51:04.207491: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-11 08:51:04.207507: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-11 08:51:04.207525: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-12-11 08:51:04.207543: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-12-11 08:51:04.207660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-11 08:51:04.208514: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-11 08:51:04.209283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-12-11 08:51:04.209360: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-12-11 08:51:05.095857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-11 08:51:05.095905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-12-11 08:51:05.095917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-12-11 08:51:05.096295: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-11 08:51:05.097268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-11 08:51:05.098156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-11 08:51:05.098973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14760 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n"
     ]
    }
   ],
   "source": [
    "path = \"/root/mobilenet_v2_ssdlite_keras/checkpoint.h5\"\n",
    "\n",
    "model =load_model(\n",
    "   path, custom_objects={\"AnchorBoxes\":AnchorBoxes},  compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340f6da3-a078-4e6f-9043-871604ec7f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8158a5c5-5e47-4577-b549-897b060734f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam, loss=ssd_loss.compute_loss, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66bad48f-726a-49ea-8f3a-a7cc06a6ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "train_dataset = DataGenerator()\n",
    "val_dataset = DataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8d9e423-9b39-4824-9ddb-a09c94272ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_dir = '/root/OIDv4_ToolKit/OID/Dataset/train_all/'\n",
    "train_annotations_dir = '/root/OIDv4_ToolKit/OID/Dataset/train_annotation/'\n",
    "train_image_set_filename = '/root/OIDv4_ToolKit/OID/Dataset/train.txt'\n",
    "\n",
    "\n",
    "test_images_dir = '/root/OIDv4_ToolKit/OID/Dataset/test_all/'\n",
    "test_annotations_dir = '/root/OIDv4_ToolKit/OID/Dataset/test_annotation/'\n",
    "test_image_set_filename     = '/root/OIDv4_ToolKit/OID/Dataset/test.txt'\n",
    "\n",
    "\n",
    "validation_images_dir = '/root/OIDv4_ToolKit/OID/Dataset/validation_all/'\n",
    "validation_annotations_dir = '/root/OIDv4_ToolKit/OID/Dataset/validation_annotation/'\n",
    "validation_image_set_filename     = '/root/OIDv4_ToolKit/OID/Dataset/validation.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3983ae06-3319-4353-859a-5ab6773db5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['Hat', 'Helmet', 'Bicycle helmet', 'Human head']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62651dac-fa82-4e68-98d7-670137d1555c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image set 'train.txt': 100%|███████████████████████████████████████████████████████| 38393/38393 [01:25<00:00, 448.50it/s]\n",
      "Processing image set 'validation.txt': 100%|████████████████████████████████████████████████████| 3530/3530 [00:06<00:00, 530.93it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset.parse_xml(\n",
    "                        images_dirs = [train_images_dir],\n",
    "                        image_set_filenames = [train_image_set_filename],\n",
    "                        annotations_dirs = [train_annotations_dir],\n",
    "                        classes = classes,\n",
    "                        include_classes = 'all',\n",
    "                        exclude_truncated = False,\n",
    "                        exclude_difficult = False,\n",
    "                        ret = False\n",
    "                        )\n",
    "\n",
    "\n",
    "val_dataset.parse_xml(images_dirs = [validation_images_dir],\n",
    "                      image_set_filenames = [validation_image_set_filename],\n",
    "                      annotations_dirs = [validation_annotations_dir],\n",
    "                      classes=classes,\n",
    "                      include_classes='all',\n",
    "                      exclude_truncated=False,\n",
    "                      exclude_difficult=False,#used to be True\n",
    "                      ret=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30d38eda-da91-4054-a2a0-31ffe13f1b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 256 # Height of the model input images\n",
    "img_width = 256 # Width of the model input images\n",
    "img_channels = 3 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71458c9b-621a-4d16-8129-a2ef661a2c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd_data_augmentation = SSDDataAugmentation(img_height=img_height,\n",
    "                                            img_width=img_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11408407-f6a6-4521-8e8a-c27a56413706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the training dataset:\t 38393\n",
      "Number of images in the validation dataset:\t  3530\n"
     ]
    }
   ],
   "source": [
    "# For the validation generator:\n",
    "convert_to_3_channels = ConvertTo3Channels()\n",
    "resize = Resize(height=img_height, width=img_width)\n",
    "\n",
    "# 5: Instantiate an encoder that can encode ground truth labels into the format needed by the SSD loss function.\n",
    "#用getlayer来获取输出层的尺寸\n",
    "# The encoder constructor needs the spatial dimensions of the model's predictor layers to create the anchor boxes.\n",
    "predictor_sizes = [model.get_layer('ssd_cls1conv2_bn').output_shape[1:3],\n",
    "                   model.get_layer('ssd_cls2conv2_bn').output_shape[1:3],\n",
    "                   model.get_layer('ssd_cls3conv2_bn').output_shape[1:3],\n",
    "                   model.get_layer('ssd_cls4conv2_bn').output_shape[1:3],\n",
    "                   model.get_layer('ssd_cls5conv2_bn').output_shape[1:3],\n",
    "                   model.get_layer('ssd_cls6conv2_bn').output_shape[1:3]]\n",
    "#encoder把ground truth labels\n",
    "ssd_input_encoder = SSDInputEncoder(img_height=img_height,\n",
    "                                    img_width=img_width,\n",
    "                                    n_classes=n_classes,\n",
    "                                    predictor_sizes=predictor_sizes,\n",
    "                                    scales=scales,\n",
    "                                    aspect_ratios_per_layer=aspect_ratios,\n",
    "                                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                                    steps=steps,\n",
    "                                    offsets=offsets,\n",
    "                                    clip_boxes=clip_boxes,\n",
    "                                    variances=variances,\n",
    "                                    matching_type='multi',\n",
    "                                    pos_iou_threshold=0.5,\n",
    "                                    neg_iou_limit=0.5,\n",
    "                                    normalize_coords=True)\n",
    "\n",
    "# 6: Create the generator handles that will be passed to Keras' `fit_generator()` function.\n",
    "\n",
    "train_generator = train_dataset.generate(batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         transformations=[ssd_data_augmentation],# used to be augumentation\n",
    "                                         label_encoder=ssd_input_encoder,\n",
    "                                         returns={'processed_images',\n",
    "                                                  'encoded_labels'},\n",
    "                                         keep_images_without_gt=False)\n",
    "\n",
    "val_generator = val_dataset.generate(batch_size=batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     transformations=[convert_to_3_channels,\n",
    "                                                      resize],\n",
    "                                     label_encoder=ssd_input_encoder,\n",
    "                                     returns={'processed_images',\n",
    "                                              'encoded_labels'},\n",
    "                                     keep_images_without_gt=False)\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ea70c3e-6633-41bc-b49b-05cf35f70bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epoch   = 0\n",
    "final_epoch     = 1000\n",
    "# steps_per_epoch = 1 #1035#6000\n",
    "steps_per_epoch = len(os.listdir('/root/OIDv4_ToolKit/OID/Dataset/train_all')) // batch_size\n",
    "val_dataset_size = len(os.listdir('/root/OIDv4_ToolKit/OID/Dataset/validation_all'))\n",
    "\n",
    "# Define model callbacks.\n",
    "# TODO: Set the filepath under which you want to save the model.\n",
    "model_checkpoint = ModelCheckpoint(filepath='/root/mobilenet_v2_ssdlite_keras/checkpoint.h5',\n",
    "                                   monitor='val_loss',#used to be val_loss\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=False,\n",
    "                                   mode='auto')\n",
    "# int(batch_size * steps_per_epoch)\n",
    "                                  \n",
    "#model_checkpoint.best = \n",
    "\n",
    "csv_logger = CSVLogger(filename='/root/mobilenet_v2_ssdlite_keras/MobileNetv2_ssdLite_training_log.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "\n",
    "# learning_rate_scheduler = LearningRateScheduler(schedule=lr_schedule,\n",
    "#                                                 verbose=1)\n",
    "\n",
    "terminate_on_nan = TerminateOnNaN()\n",
    "\n",
    "callbacks = [model_checkpoint,\n",
    "             csv_logger,\n",
    "             # learning_rate_scheduler,\n",
    "             terminate_on_nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6066b6-ba31-4e92-b78b-5c5eb4adc2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 08:53:05.638156: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-12-11 08:53:05.639358: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 1999995000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "Tensor(\"Neg:0\", shape=(None, 1536), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 08:53:18.199028: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-12-11 08:53:21.171501: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-12-11 08:53:21.823242: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 3679s 12s/step - loss: 3.9142 - accuracy: 0.4309 - val_loss: 3.4870 - val_accuracy: 0.3325\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.48705, saving model to /root/mobilenet_v2_ssdlite_keras/checkpoint.h5\n",
      "Epoch 2/1000\n",
      "299/299 [==============================] - 3598s 12s/step - loss: 3.8960 - accuracy: 0.4306 - val_loss: 3.5624 - val_accuracy: 0.3167\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 3.48705\n",
      "Epoch 3/1000\n",
      "299/299 [==============================] - 3549s 12s/step - loss: 3.8657 - accuracy: 0.4285 - val_loss: 3.5169 - val_accuracy: 0.3185\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3.48705\n",
      "Epoch 4/1000\n",
      "299/299 [==============================] - 3532s 12s/step - loss: 3.8665 - accuracy: 0.4294 - val_loss: 3.5509 - val_accuracy: 0.3346\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 3.48705\n",
      "Epoch 5/1000\n",
      "299/299 [==============================] - 3566s 12s/step - loss: 3.8719 - accuracy: 0.4325 - val_loss: 3.7695 - val_accuracy: 0.3636\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3.48705\n",
      "Epoch 6/1000\n",
      "299/299 [==============================] - 3631s 12s/step - loss: 3.8865 - accuracy: 0.4323 - val_loss: 3.6482 - val_accuracy: 0.3376\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3.48705\n",
      "Epoch 7/1000\n",
      "299/299 [==============================] - 3653s 12s/step - loss: 3.8959 - accuracy: 0.4329 - val_loss: 3.5463 - val_accuracy: 0.3450\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3.48705\n",
      "Epoch 8/1000\n",
      "299/299 [==============================] - 3671s 12s/step - loss: 3.8796 - accuracy: 0.4364 - val_loss: 3.4301 - val_accuracy: 0.3438\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.48705 to 3.43010, saving model to /root/mobilenet_v2_ssdlite_keras/checkpoint.h5\n",
      "Epoch 9/1000\n",
      "299/299 [==============================] - 3574s 12s/step - loss: 3.8766 - accuracy: 0.4344 - val_loss: 3.4319 - val_accuracy: 0.3575\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.43010\n",
      "Epoch 10/1000\n",
      "299/299 [==============================] - 3599s 12s/step - loss: 3.8750 - accuracy: 0.4349 - val_loss: 3.5230 - val_accuracy: 0.3589\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.43010\n",
      "Epoch 11/1000\n",
      "299/299 [==============================] - 3665s 12s/step - loss: 3.8897 - accuracy: 0.4304 - val_loss: 3.8372 - val_accuracy: 0.3247\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 3.43010\n",
      "Epoch 12/1000\n",
      "299/299 [==============================] - 3682s 12s/step - loss: 3.8092 - accuracy: 0.4325 - val_loss: 3.5978 - val_accuracy: 0.3619\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.43010\n",
      "Epoch 13/1000\n",
      "299/299 [==============================] - 3594s 12s/step - loss: 3.8412 - accuracy: 0.4342 - val_loss: 3.5531 - val_accuracy: 0.3453\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 3.43010\n",
      "Epoch 14/1000\n",
      "171/299 [================>.............] - ETA: 24:52 - loss: 3.8370 - accuracy: 0.4323"
     ]
    }
   ],
   "source": [
    "# with tf.device('/device:GPU:0'):\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(train_generator,\n",
    "                        steps_per_epoch = steps_per_epoch,\n",
    "                        epochs = final_epoch,\n",
    "                        callbacks = callbacks,\n",
    "                        validation_data = val_generator,\n",
    "                        validation_steps = val_dataset_size//batch_size,\n",
    "                        initial_epoch = initial_epoch,\n",
    "                        verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbd8b3c-85db-40d2-8a35-d9b56a68b411",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jun_env",
   "language": "python",
   "name": "jun_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
